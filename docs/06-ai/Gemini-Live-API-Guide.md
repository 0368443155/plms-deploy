# Gemini Live API - Unlimited Models Guide

## ğŸ“‹ Tá»•ng quan

CÃ¡c model "unlimited" báº¡n tháº¥y trong Google AI Studio (`gemini-2.5-flash-live`, `gemini-2.0-flash-live`, `gemini-2.5-flash-native-audio-dialog`) lÃ  **Multimodal Live API models**.

### âš ï¸ KhÃ¡c biá»‡t quan trá»ng:

| Feature | Standard API (`generateContent`) | Live API (Unlimited Models) |
|---------|----------------------------------|----------------------------|
| **Method** | `generateContent()` | WebSocket streaming |
| **Use Case** | Text generation, chat | Real-time audio/video/text streaming |
| **Quota** | Limited (cÃ³ giá»›i háº¡n) | **Unlimited** (khÃ´ng giá»›i háº¡n) |
| **Latency** | ~1-2s | ~600ms (real-time) |
| **Input** | Text, images (static) | Audio, video, text (streaming) |
| **Output** | Text | Text, audio (streaming) |

## âœ… Khi nÃ o dÃ¹ng Live API?

Live API phÃ¹ há»£p cho:
- âœ… Real-time voice assistants
- âœ… Video call vá»›i AI
- âœ… Screen sharing + AI analysis
- âœ… Interactive chatbots vá»›i audio
- âœ… **Text chat vá»›i low latency** (cÃ³ thá»ƒ dÃ¹ng!)

## âŒ Khi nÃ o KHÃ”NG nÃªn dÃ¹ng Live API?

- âŒ Simple text generation (dÃ¹ng `generateContent` Ä‘Æ¡n giáº£n hÆ¡n)
- âŒ Batch processing
- âŒ KhÃ´ng cáº§n real-time response

## ğŸš€ CÃ¡ch implement Live API cho Text Chat

### 1. CÃ i Ä‘áº·t dependencies

```bash
npm install ws @google/generative-ai
```

### 2. Backend - WebSocket Handler

```typescript
// convex/ai-live.ts
import { GoogleGenerativeAI } from "@google/generative-ai";
import WebSocket from "ws";

export async function chatWithLiveAPI(
  message: string,
  documentContext: string,
  history: Array<{ role: string; content: string }>
) {
  const apiKey = process.env.GEMINI_API_KEY;
  if (!apiKey) throw new Error("GEMINI_API_KEY not configured");

  const genAI = new GoogleGenerativeAI(apiKey);
  
  // Use unlimited model
  const model = genAI.getGenerativeModel({ 
    model: "gemini-2.5-flash-live" 
  });

  // Create WebSocket connection
  const ws = new WebSocket(
    `wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1alpha.GenerativeService.BidiGenerateContent`,
    {
      headers: {
        "Content-Type": "application/json",
        "x-goog-api-key": apiKey,
      },
    }
  );

  return new Promise((resolve, reject) => {
    let response = "";

    ws.on("open", () => {
      // Send setup message
      ws.send(JSON.stringify({
        setup: {
          model: "models/gemini-2.5-flash-live",
          generation_config: {
            response_modalities: ["TEXT"],
          },
        },
      }));

      // Send context
      ws.send(JSON.stringify({
        client_content: {
          turns: [
            {
              role: "user",
              parts: [{ text: `Context: ${documentContext}` }],
            },
            ...history.map(h => ({
              role: h.role,
              parts: [{ text: h.content }],
            })),
            {
              role: "user",
              parts: [{ text: message }],
            },
          ],
          turn_complete: true,
        },
      }));
    });

    ws.on("message", (data) => {
      const msg = JSON.parse(data.toString());
      
      if (msg.serverContent?.modelTurn) {
        const parts = msg.serverContent.modelTurn.parts;
        parts.forEach((part: any) => {
          if (part.text) {
            response += part.text;
          }
        });
      }

      if (msg.serverContent?.turnComplete) {
        ws.close();
        resolve(response);
      }
    });

    ws.on("error", (error) => {
      reject(error);
    });

    ws.on("close", () => {
      if (response) {
        resolve(response);
      } else {
        reject(new Error("Connection closed without response"));
      }
    });
  });
}
```

### 3. Integrate vÃ o existing code

```typescript
// Trong summarizeDocumentHandler hoáº·c chatWithAIHandler
if (!summary) {
  // Try Live API as fallback
  console.log("Trying Gemini Live API (unlimited)...");
  try {
    summary = await chatWithLiveAPI(
      "TÃ³m táº¯t ná»™i dung nÃ y",
      plainText,
      []
    );
    usedModel = "gemini-2.5-flash-live (unlimited)";
    console.log("Successfully used Live API");
  } catch (liveError: any) {
    console.error("Live API failed:", liveError);
    // Continue to SambaNova fallback
  }
}
```

## ğŸ“Š So sÃ¡nh Performance

| Metric | Standard API | Live API |
|--------|--------------|----------|
| First token | ~1-2s | ~600ms |
| Quota | 15 RPM (free) | **Unlimited** |
| Complexity | Low | Medium |
| Setup | Simple | WebSocket |

## ğŸ¯ Káº¿t luáº­n

**Hiá»‡n táº¡i:**
- âœ… DÃ¹ng `gemini-2.0-flash-exp` vÃ  `gemini-1.5-flash` (Ä‘Æ¡n giáº£n, Ä‘á»§ dÃ¹ng)
- âœ… Fallback sang SambaNova khi quota exceeded (Ä‘ang hoáº¡t Ä‘á»™ng tá»‘t)

**TÆ°Æ¡ng lai (náº¿u cáº§n unlimited):**
- ğŸ”„ Implement Live API vá»›i WebSocket
- ğŸ”„ Phá»©c táº¡p hÆ¡n nhÆ°ng khÃ´ng giá»›i háº¡n quota
- ğŸ”„ Latency tháº¥p hÆ¡n (~600ms vs ~1-2s)

## ğŸ“š TÃ i liá»‡u tham kháº£o

- [Gemini Live API Documentation](https://ai.google.dev/gemini-api/docs/live-api)
- [WebSocket Integration Guide](https://ai.google.dev/gemini-api/docs/live-api/websocket)
- [Partner Integrations (LiveKit, Daily)](https://ai.google.dev/gemini-api/docs/live-api/partners)

## ğŸ’¡ Gá»£i Ã½

Vá»›i use case hiá»‡n táº¡i (text chat/summary), **khÃ´ng cáº§n thiáº¿t** pháº£i dÃ¹ng Live API vÃ¬:
1. Standard API Ä‘Æ¡n giáº£n hÆ¡n nhiá»u
2. SambaNova fallback Ä‘Ã£ hoáº¡t Ä‘á»™ng tá»‘t
3. Latency 1-2s lÃ  cháº¥p nháº­n Ä‘Æ°á»£c cho text generation

**Chá»‰ implement Live API khi:**
- Cáº§n real-time voice/video interaction
- Cáº§n latency < 1s
- VÆ°á»£t quÃ¡ quota cá»§a táº¥t cáº£ standard models
